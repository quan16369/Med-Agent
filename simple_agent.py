"""
Simple Agent Interface - Focus on Core Agent Functionality
Lo·∫°i b·ªè c√°c th√†nh ph·∫ßn production-ready, ch·ªâ t·∫≠p trung v√†o agent workflow
"""

from typing import Optional, Dict, Any, List
import logging
from pathlib import Path

from medassist.config import get_config
from medassist.logging_utils import setup_logging, get_logger
from medassist.agentic_orchestrator import AgenticMedicalOrchestrator
from medassist.ingestion_pipeline import IngestionPipeline
from medassist.multimodal_models import MultimodalMessage, TextContent, ImageUrlContent

# Setup logging
setup_logging()
logger = get_logger(__name__)


class SimpleAgent:
    """
    Simple agent interface t·∫≠p trung v√†o core functionality
    Kh√¥ng c√≥ rate limiting, health checks, hay production overhead
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """Initialize agent with basic configuration"""
        self.config = get_config(config_path)
        self.orchestrator = AgenticMedicalOrchestrator(self.config)
        self.ingestion_pipeline = IngestionPipeline(self.config)
        logger.info("‚úÖ Simple Agent initialized")
    
    def ask(self, question: str, context: Optional[str] = None) -> Dict[str, Any]:
        """
        ƒê∆°n gi·∫£n h√≥a: h·ªèi c√¢u h·ªèi v√† nh·∫≠n c√¢u tr·∫£ l·ªùi
        
        Args:
            question: C√¢u h·ªèi medical
            context: Context b·ªï sung (optional)
            
        Returns:
            Dict v·ªõi answer, reasoning, entities, relationships
        """
        try:
            logger.info(f"‚ùì Question: {question}")
            
            # Execute agent workflow
            result = self.orchestrator.process_query(
                question=question,
                context=context
            )
            
            logger.info(f"‚úÖ Answer generated successfully")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Error: {e}")
            return {
                "answer": f"Error processing question: {str(e)}",
                "error": str(e),
                "success": False
            }
    
    def ask_with_image(
        self, 
        question: str, 
        image_path: Optional[str] = None,
        image_base64: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        H·ªèi v·ªõi image (X-ray, CT, MRI, etc.)
        
        Args:
            question: C√¢u h·ªèi v·ªÅ image
            image_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn image file
            image_base64: Base64 encoded image
            
        Returns:
            Dict v·ªõi answer v√† visual analysis
        """
        try:
            # Convert image to multimodal format
            if image_path:
                with open(image_path, 'rb') as f:
                    import base64
                    image_data = base64.b64encode(f.read()).decode('utf-8')
            elif image_base64:
                image_data = image_base64
            else:
                raise ValueError("C·∫ßn image_path ho·∫∑c image_base64")
            
            # Create multimodal message
            message = MultimodalMessage(content=[
                TextContent(text=question),
                ImageUrlContent(url=f"data:image/jpeg;base64,{image_data}")
            ])
            
            logger.info(f"üñºÔ∏è Multimodal question: {question}")
            
            # Process with multimodal support
            result = self.orchestrator.process_query(
                question=question,
                multimodal_content=message
            )
            
            logger.info(f"‚úÖ Multimodal answer generated")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Multimodal error: {e}")
            return {
                "answer": f"Error processing multimodal question: {str(e)}",
                "error": str(e),
                "success": False
            }
    
    def ingest_document(
        self, 
        text: str, 
        doc_id: Optional[str] = None,
        metadata: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        ƒê∆∞a document v√†o knowledge graph
        
        Args:
            text: N·ªôi dung document
            doc_id: ID c·ªßa document
            metadata: Metadata b·ªï sung
            
        Returns:
            Dict v·ªõi entities v√† relationships extracted
        """
        try:
            logger.info(f"üìÑ Ingesting document: {doc_id or 'unnamed'}")
            
            # Process document through ingestion pipeline
            result = self.ingestion_pipeline.process_document(
                text=text,
                doc_id=doc_id,
                metadata=metadata or {}
            )
            
            logger.info(f"‚úÖ Document ingested: {result.get('entity_count', 0)} entities, {result.get('relationship_count', 0)} relationships")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Ingestion error: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def ingest_multimodal_document(
        self,
        text: str,
        images: List[Dict[str, Any]],
        doc_id: Optional[str] = None,
        metadata: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        Ingest document with images (case studies, medical reports)
        
        Args:
            text: Document text
            images: List of {base64, metadata} dicts
            doc_id: Document ID
            metadata: Additional metadata
            
        Returns:
            Dict with extraction results
        """
        try:
            logger.info(f"üìÑüñºÔ∏è Ingesting multimodal document: {doc_id or 'unnamed'} with {len(images)} images")
            
            # Convert to multimodal format
            multimodal_content = {
                "text": text,
                "images": images
            }
            
            result = self.ingestion_pipeline.process_document(
                text=multimodal_content,
                doc_id=doc_id,
                metadata=metadata or {}
            )
            
            logger.info(f"‚úÖ Multimodal document ingested")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Multimodal ingestion error: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def explore_knowledge_graph(
        self, 
        entity_name: str, 
        max_depth: int = 2
    ) -> Dict[str, Any]:
        """
        Explore knowledge graph around an entity
        
        Args:
            entity_name: T√™n entity c·∫ßn explore
            max_depth: ƒê·ªô s√¢u t·ªëi ƒëa ƒë·ªÉ traverse
            
        Returns:
            Dict v·ªõi entities v√† relationships li√™n quan
        """
        try:
            logger.info(f"üîç Exploring KG for: {entity_name}")
            
            # Use graph retrieval
            from medassist.graph_retrieval import GraphConditionalRetrieval
            graph_retriever = GraphConditionalRetrieval(
                self.orchestrator.knowledge_graph
            )
            
            result = graph_retriever.explore_entity(
                entity_name=entity_name,
                max_depth=max_depth
            )
            
            logger.info(f"‚úÖ Found {len(result.get('related_entities', []))} related entities")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Exploration error: {e}")
            return {
                "success": False,
                "error": str(e)
            }


def demo_simple_agent():
    """Demo usage c·ªßa Simple Agent"""
    
    print("=" * 60)
    print("ü§ñ Simple Medical Agent Demo")
    print("=" * 60)
    
    # Initialize agent
    agent = SimpleAgent()
    
    # Example 1: Simple Q&A
    print("\n1Ô∏è‚É£ Simple Medical Q&A")
    print("-" * 60)
    result1 = agent.ask(
        question="What are the symptoms of diabetes?",
        context="Patient is 45 years old with family history"
    )
    print(f"Answer: {result1.get('answer', 'N/A')}")
    
    # Example 2: Ingest document
    print("\n2Ô∏è‚É£ Document Ingestion")
    print("-" * 60)
    result2 = agent.ingest_document(
        text="Diabetes mellitus causes hyperglycemia. Metformin treats diabetes by reducing glucose production.",
        doc_id="doc_001",
        metadata={"source": "medical_textbook"}
    )
    print(f"Extracted: {result2.get('entity_count', 0)} entities, {result2.get('relationship_count', 0)} relationships")
    
    # Example 3: Explore knowledge graph
    print("\n3Ô∏è‚É£ Knowledge Graph Exploration")
    print("-" * 60)
    result3 = agent.explore_knowledge_graph(
        entity_name="diabetes",
        max_depth=2
    )
    print(f"Found {len(result3.get('related_entities', []))} related entities")
    
    # Example 4: Multimodal Q&A (if image available)
    print("\n4Ô∏è‚É£ Multimodal Q&A (v·ªõi image)")
    print("-" * 60)
    print("Skipped - requires actual medical image")
    
    print("\n" + "=" * 60)
    print("‚úÖ Demo completed!")
    print("=" * 60)


if __name__ == "__main__":
    demo_simple_agent()
